{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/doong/Desktop/PythonWorkspace/운송량예측공모전/train(전처리 끝).csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Users/doong/Desktop/PythonWorkspace/운송량예측공모전/test(전처리 끝).csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('C:/Users/doong/Desktop/공모전/운송량 예측/235867_택배 운송량 예측 경진대회/sample_submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'SEND_SPG_INNB', 'REC_SPG_INNB', 'INVC_CONT',\n",
       "       'label_MCLS', 'label_LCLS', 'DL_GD_LCLS_NM_0', 'DL_GD_LCLS_NM_1',\n",
       "       'DL_GD_LCLS_NM_2', 'DL_GD_LCLS_NM_3', 'DL_GD_LCLS_NM_4',\n",
       "       'DL_GD_LCLS_NM_5', 'DL_GD_MCLS_NM_0', 'DL_GD_MCLS_NM_1',\n",
       "       'DL_GD_MCLS_NM_2', 'DL_GD_MCLS_NM_3', 'DL_GD_MCLS_NM_4',\n",
       "       'DL_GD_MCLS_NM_5', 'DL_GD_MCLS_NM_6', 'DL_GD_MCLS_NM_7',\n",
       "       'DL_GD_MCLS_NM_8', 'DL_GD_MCLS_NM_9', 'DL_GD_MCLS_NM_10',\n",
       "       'DL_GD_MCLS_NM_11', 'DL_GD_MCLS_NM_12', 'DL_GD_MCLS_NM_13',\n",
       "       'DL_GD_MCLS_NM_14', 'DL_GD_MCLS_NM_15', 'DL_GD_MCLS_NM_16',\n",
       "       'DL_GD_MCLS_NM_17', 'DL_GD_MCLS_NM_18', 'DL_GD_MCLS_NM_19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'SEND_SPG_INNB', 'REC_SPG_INNB', 'label_MCLS',\n",
       "       'label_LCLS', 'DL_GD_LCLS_NM_0', 'DL_GD_LCLS_NM_1', 'DL_GD_LCLS_NM_2',\n",
       "       'DL_GD_LCLS_NM_3', 'DL_GD_LCLS_NM_4', 'DL_GD_LCLS_NM_5',\n",
       "       'DL_GD_MCLS_NM_0', 'DL_GD_MCLS_NM_1', 'DL_GD_MCLS_NM_2',\n",
       "       'DL_GD_MCLS_NM_3', 'DL_GD_MCLS_NM_4', 'DL_GD_MCLS_NM_5',\n",
       "       'DL_GD_MCLS_NM_6', 'DL_GD_MCLS_NM_7', 'DL_GD_MCLS_NM_8',\n",
       "       'DL_GD_MCLS_NM_9', 'DL_GD_MCLS_NM_10', 'DL_GD_MCLS_NM_11',\n",
       "       'DL_GD_MCLS_NM_12', 'DL_GD_MCLS_NM_13', 'DL_GD_MCLS_NM_14',\n",
       "       'DL_GD_MCLS_NM_15', 'DL_GD_MCLS_NM_16', 'DL_GD_MCLS_NM_17',\n",
       "       'DL_GD_MCLS_NM_18', 'DL_GD_MCLS_NM_19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"Unnamed: 0\", 'label_MCLS', 'label_LCLS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop([\"Unnamed: 0\",'index', 'label_MCLS', 'label_LCLS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,3:]\n",
    "y = train[\"INVC_CONT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, X_test, y_, y_test = train_test_split(X, y, test_size = 0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# def count_and_plot(y): \n",
    "#     counter = Counter(y)\n",
    "#     for k,v in counter.items():\n",
    "#         print('Class=%s, n=%d (%.3f%%)' % (k, v, v / len(y) * 100))\n",
    "#     pyplot.bar(counter.keys(), counter.values())\n",
    "#     pyplot.show()\n",
    "\n",
    "# count_and_plot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import OneSidedSelection\n",
    "# # 언더샘플링\n",
    "# OSS = OneSidedSelection(random_state = 0)\n",
    "# X_train, y_train = OSS.fit_resample(X['label'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE\n",
    "# def rmse(y_true, y_pred):\n",
    "#     rmse = K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "#     return rmse\n",
    "\n",
    "# # MAPE\n",
    "# def mean_absolute_percentage_error(y_test, y_pred):\n",
    "#     y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "#     return np.mean(np.abs((y_test - y_pred) / y_test)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dense_nparams : 초기 dense layer size\n",
    "# dense_nparams = [256, 512, 1024]\n",
    "\n",
    "# # dense_layer_sizes : 사용할 dense layer size 목록\n",
    "# dense_layer_sizes = [(16,), (16,16,), (16,16,16,)]\n",
    "\n",
    "# # input_optimizer = optimizer\n",
    "# input_optimizer = [RMSprop, Adam]\n",
    "\n",
    "# # input_kernel_initializer : 가중치 초기화 방법\n",
    "# input_kernel_initializer =  ['he_normal' ]\n",
    "\n",
    "# # input_dropout : dropout 비율\n",
    "# input_dropout = [0.1]\n",
    "\n",
    "# # input_lr : learning_rate\n",
    "# input_lr = [0.001]\n",
    "\n",
    "# # hyperparameter 를 dictionary 화\n",
    "# param_grid = dict(dense_nparams = dense_nparams,\n",
    "#                 dense_layer_sizes = dense_layer_sizes,\n",
    "#                 input_optimizer = input_optimizer,\n",
    "#                 input_kernel_initializer = input_kernel_initializer,\n",
    "#                 input_dropout = input_dropout,\n",
    "#                 input_lr = input_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyperparameter tuning 대상 정의\n",
    "# def create_model(dense_nparams, dense_layer_sizes , input_optimizer, input_kernel_initializer, input_dropout, input_lr):\n",
    "\n",
    "#     model=Sequential()\n",
    "#     model.add(layers.Dense(dense_nparams, activation=\"relu\", input_shape=(X_train.shape[1],), kernel_initializer=input_kernel_initializer))  \n",
    "#     model.add(layers.Dropout(input_dropout),)\n",
    "\n",
    "#     # dense_layer_sizes 만큼 layer 추가\n",
    "#     for layer_size in dense_layer_sizes:\n",
    "#         model.add(layers.Dense(layer_size, activation='relu', kernel_initializer=input_kernel_initializer))\n",
    "#         model.add(layers.Dropout(input_dropout), )\n",
    "\n",
    "#     model.add(layers.Dense(1))\n",
    "\n",
    "#     optimizer = input_optimizer(lr=input_lr)\n",
    "\n",
    "#     model.compile(optimizer = optimizer ,\n",
    "#                   loss='mape',\n",
    "#                   metrics=['mape',rmse])\n",
    "#     return model\n",
    "\n",
    "# # hyperparameter tuning 대상 선언\n",
    "# # 파라미터 조합 당 epochs 는 300 번, batch_size 는 10\n",
    "# regressor_model = KerasRegressor(build_fn=create_model, epochs=300, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross_validation 정의\n",
    "# kf = KFold(random_state=30,\n",
    "#            n_splits=10, # Fold 는 10개로 지정\n",
    "#            shuffle=True\n",
    "#           )\n",
    "\n",
    "# # gridsearch 정의\n",
    "# # scoring : 검증셋의 성능을 무엇으로 측정할 것인지\n",
    "# # n_jobs : 프로세스가 시스템의 모든 코어를 사용하도록    \n",
    "# # verbose : 모든 log 출력하도록\n",
    "# grid = GridSearchCV(estimator=regressor_model, \n",
    "#                     param_grid=param_grid, \n",
    "#                     scoring = make_scorer(mean_absolute_percentage_error, greater_is_better=False),\n",
    "#                     cv = kf,\n",
    "#                     n_jobs=-1,\n",
    "#                     verbose=3)\n",
    "\n",
    "# # gridsearch 시작\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# # gridesearch 결과\n",
    "# print(\"최고의 파라미터 :\", grid_result.best_params_)\n",
    "# print(\"최고 평균 정확도 : {}\".format(grid_result.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 정의\n",
    "# result_model = create_model(grid_result.best_params_['dense_nparams'],\n",
    "#                             grid_result.best_params_['dense_layer_sizes'],\n",
    "#                             grid_result.best_params_['input_optimizer'],\n",
    "#                             grid_result.best_params_['input_kernel_initializer'],\n",
    "#                             grid_result.best_params_['input_dropout'],\n",
    "#                             grid_result.best_params_['input_lr'])\n",
    "# # 모델 훈련\n",
    "# result_model.fit(X_train, \n",
    "#                 y_train,\n",
    "#                 epochs=300, \n",
    "#                 validation_split = 0.1, \n",
    "#                 verbose =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 훈련데이터 예측\n",
    "# y_train_pred = result_model.predict(X_train).reshape(-1,)\n",
    "# print(\"훈련데이터 예측 rmse : {}\\n\".format(rmse(y_train,y_train_pred)))\n",
    "\n",
    "# # 테스트데이터 예측\n",
    "# y_test_pred = result_model.predict(X_test).reshape(-1,)\n",
    "# print(\"테스트데이터 예측 rmse : {}\\n\".format(rmse(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구조 정의하기\n",
    "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
    "model = tf.keras.Sequential()  #순차적 계층화 준비\n",
    "model.add(layers.Dense(20, input_shape=(26,)))  # 입력 20개로부터 전달받는 32개 노드의 layer 생성\n",
    "model.add(layers.Activation('relu'))  #ReLU 활성화함수 채택\n",
    "model.add(layers.Dropout(0.1))        #dropout ratio=10% (배치 훈련시 10% arc 무시)\n",
    "\n",
    "model.add(layers.Dense(14))         \n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('linear')) \n",
    "# 모델 구축하기\n",
    "model.compile(\n",
    "    loss='mse',  #다중 교차엔트로피\n",
    "    optimizer=\"adam\",   #최적화 기법 중 하나\n",
    "    metrics=['mae'])  #정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "179/179 [==============================] - 2s 4ms/step - loss: 9.6449 - mae: 2.3932 - val_loss: 3.5465 - val_mae: 1.2172\n",
      "Epoch 2/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.5451 - mae: 1.2920 - val_loss: 3.3060 - val_mae: 1.1984\n",
      "Epoch 3/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.4430 - mae: 1.2704 - val_loss: 3.3092 - val_mae: 1.1923\n",
      "Epoch 4/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.3962 - mae: 1.2609 - val_loss: 3.3002 - val_mae: 1.2042\n",
      "Epoch 5/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.3528 - mae: 1.2497 - val_loss: 3.3035 - val_mae: 1.2045\n",
      "Epoch 6/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.3663 - mae: 1.2535 - val_loss: 3.2964 - val_mae: 1.2071\n",
      "Epoch 7/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.3218 - mae: 1.2407 - val_loss: 3.2917 - val_mae: 1.2156\n",
      "Epoch 8/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.3527 - mae: 1.2477 - val_loss: 3.3153 - val_mae: 1.1931\n",
      "Epoch 9/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.3635 - mae: 1.2446 - val_loss: 3.2934 - val_mae: 1.2130\n",
      "Epoch 10/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.3313 - mae: 1.2437 - val_loss: 3.2969 - val_mae: 1.2067\n",
      "Epoch 11/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.3191 - mae: 1.2388 - val_loss: 3.2931 - val_mae: 1.2122\n",
      "Epoch 12/500\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 3.3030 - mae: 1.2369 - val_loss: 3.3064 - val_mae: 1.1998\n",
      "Epoch 13/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.2502 - mae: 1.2277 - val_loss: 3.2904 - val_mae: 1.2219\n",
      "Epoch 14/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.2696 - mae: 1.2319 - val_loss: 3.3063 - val_mae: 1.2028\n",
      "Epoch 15/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.2974 - mae: 1.2299 - val_loss: 3.2980 - val_mae: 1.2081\n",
      "Epoch 16/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.2573 - mae: 1.2249 - val_loss: 3.3052 - val_mae: 1.2033\n",
      "Epoch 17/500\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 3.2473 - mae: 1.2247 - val_loss: 3.3104 - val_mae: 1.1993\n",
      "Epoch 18/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.2523 - mae: 1.2169 - val_loss: 3.2922 - val_mae: 1.2181\n",
      "Epoch 19/500\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 3.2367 - mae: 1.2190 - val_loss: 3.3275 - val_mae: 1.1878\n",
      "Epoch 20/500\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 3.2196 - mae: 1.2133 - val_loss: 3.2915 - val_mae: 1.2147\n",
      "Epoch 21/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.2334 - mae: 1.2149 - val_loss: 3.3018 - val_mae: 1.2040\n",
      "Epoch 22/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.2281 - mae: 1.2120 - val_loss: 3.3030 - val_mae: 1.2046\n",
      "Epoch 23/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.1987 - mae: 1.2097 - val_loss: 3.3103 - val_mae: 1.1974\n",
      "Epoch 24/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1855 - mae: 1.2034 - val_loss: 3.3132 - val_mae: 1.1934\n",
      "Epoch 25/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1861 - mae: 1.2042 - val_loss: 3.2933 - val_mae: 1.2113\n",
      "Epoch 26/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1733 - mae: 1.2039 - val_loss: 3.2889 - val_mae: 1.2135\n",
      "Epoch 27/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1414 - mae: 1.2004 - val_loss: 3.3011 - val_mae: 1.2035\n",
      "Epoch 28/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1536 - mae: 1.1992 - val_loss: 3.2936 - val_mae: 1.2116\n",
      "Epoch 29/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1672 - mae: 1.1987 - val_loss: 3.2893 - val_mae: 1.2151\n",
      "Epoch 30/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1455 - mae: 1.1959 - val_loss: 3.2930 - val_mae: 1.2125\n",
      "Epoch 31/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.1495 - mae: 1.1980 - val_loss: 3.2910 - val_mae: 1.2128\n",
      "Epoch 32/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1282 - mae: 1.1951 - val_loss: 3.2902 - val_mae: 1.2184\n",
      "Epoch 33/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1245 - mae: 1.1958 - val_loss: 3.2987 - val_mae: 1.2063\n",
      "Epoch 34/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1278 - mae: 1.1943 - val_loss: 3.3148 - val_mae: 1.1942\n",
      "Epoch 35/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1196 - mae: 1.1891 - val_loss: 3.2984 - val_mae: 1.2052\n",
      "Epoch 36/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1017 - mae: 1.1890 - val_loss: 3.2877 - val_mae: 1.2227\n",
      "Epoch 37/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1005 - mae: 1.1886 - val_loss: 3.3032 - val_mae: 1.2031\n",
      "Epoch 38/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1059 - mae: 1.1900 - val_loss: 3.3120 - val_mae: 1.1964\n",
      "Epoch 39/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0798 - mae: 1.1857 - val_loss: 3.3032 - val_mae: 1.2030\n",
      "Epoch 40/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0902 - mae: 1.1831 - val_loss: 3.3014 - val_mae: 1.2030\n",
      "Epoch 41/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.0767 - mae: 1.1848 - val_loss: 3.3005 - val_mae: 1.2061\n",
      "Epoch 42/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0694 - mae: 1.1825 - val_loss: 3.3022 - val_mae: 1.2022\n",
      "Epoch 43/500\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0784 - mae: 1.183 - 1s 3ms/step - loss: 3.0696 - mae: 1.1820 - val_loss: 3.2953 - val_mae: 1.2135\n",
      "Epoch 44/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0732 - mae: 1.1842 - val_loss: 3.2873 - val_mae: 1.2284\n",
      "Epoch 45/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0645 - mae: 1.1793 - val_loss: 3.2975 - val_mae: 1.2099\n",
      "Epoch 46/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0672 - mae: 1.1777 - val_loss: 3.2850 - val_mae: 1.2286\n",
      "Epoch 47/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.0538 - mae: 1.1812 - val_loss: 3.2883 - val_mae: 1.2220\n",
      "Epoch 48/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0536 - mae: 1.1791 - val_loss: 3.2903 - val_mae: 1.2188\n",
      "Epoch 49/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0444 - mae: 1.1742 - val_loss: 3.2886 - val_mae: 1.2232\n",
      "Epoch 50/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0534 - mae: 1.1803 - val_loss: 3.2981 - val_mae: 1.2058\n",
      "Epoch 51/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0317 - mae: 1.1748 - val_loss: 3.2852 - val_mae: 1.2271\n",
      "Epoch 52/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0487 - mae: 1.1790 - val_loss: 3.2960 - val_mae: 1.2105\n",
      "Epoch 53/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0584 - mae: 1.1804 - val_loss: 3.2896 - val_mae: 1.2202\n",
      "Epoch 54/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0383 - mae: 1.1734 - val_loss: 3.2912 - val_mae: 1.2184\n",
      "Epoch 55/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0428 - mae: 1.1779 - val_loss: 3.2974 - val_mae: 1.2087\n",
      "Epoch 56/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0332 - mae: 1.1782 - val_loss: 3.2912 - val_mae: 1.2212\n",
      "Epoch 57/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0372 - mae: 1.1727 - val_loss: 3.2873 - val_mae: 1.2292\n",
      "Epoch 58/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0319 - mae: 1.1772 - val_loss: 3.2874 - val_mae: 1.2216\n",
      "Epoch 59/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0281 - mae: 1.1781 - val_loss: 3.2996 - val_mae: 1.2063\n",
      "Epoch 60/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0290 - mae: 1.1724 - val_loss: 3.2965 - val_mae: 1.2116\n",
      "Epoch 61/500\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.0323 - mae: 1.1773 - val_loss: 3.2983 - val_mae: 1.2085\n",
      "Epoch 62/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0307 - mae: 1.1745 - val_loss: 3.2897 - val_mae: 1.2240\n",
      "Epoch 63/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0178 - mae: 1.1754 - val_loss: 3.2882 - val_mae: 1.2290\n",
      "Epoch 64/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0188 - mae: 1.1766 - val_loss: 3.2903 - val_mae: 1.2202\n",
      "Epoch 65/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0306 - mae: 1.1766 - val_loss: 3.2909 - val_mae: 1.2189\n",
      "Epoch 66/500\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.0221 - mae: 1.1751 - val_loss: 3.2997 - val_mae: 1.2062\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 3.4796 - mae: 1.2233\n",
      "test_loss:  3.4795925617218018\n",
      "test_mae:  1.2232502698898315\n"
     ]
    }
   ],
   "source": [
    "# 데이터 훈련하기\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,  #100개에 한 번씩 업데이터 실행\n",
    "    epochs=500,       #훈련 데이터셋을 총 50회 반복 실험. 단, 조기중지될 수 있음\n",
    "    validation_split=0.1,  \n",
    "      #validation data 분할 비율. 즉, 15000개 중에서 20%인 3000개를 validation용으로 분할\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)],  \n",
    "      #'val_loss'를 monitor하여 감소하면 한 번 더(1) 참고 조기중지\n",
    "    verbose=1)  #전 과정을 화면에 출력(1) 또는 미출력(0) 모드\n",
    "\n",
    "# 테스트 데이터로 평가하기\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('test_loss: ', score[0]) # loss\n",
    "print('test_mae: ', score[1]) # rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test.iloc[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss[\"INVC_CONT\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>INVC_CONT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>36635</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>36636</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>36637</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>36638</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>36639</td>\n",
       "      <td>3.760425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  INVC_CONT\n",
       "0     32000   3.760425\n",
       "1     32001   3.760425\n",
       "2     32002   3.760425\n",
       "3     32003   3.760425\n",
       "4     32004   3.760425\n",
       "...     ...        ...\n",
       "4635  36635   3.760425\n",
       "4636  36636   3.760425\n",
       "4637  36637   3.760425\n",
       "4638  36638   3.760425\n",
       "4639  36639   3.760425\n",
       "\n",
       "[4640 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.drop(\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv(\"sample_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60499b81eba5d675b2e5eb8d2b35aff941171ec97d5f91757c93f4a89cfafe09"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
